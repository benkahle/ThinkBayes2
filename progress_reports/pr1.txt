Ben Kahle
9/11/14
Bayesian
	I spent the majority of this week getting an initial understanding of the Bayesian approach to problem solving and leverage a basic computational method of problem solving. I specifically appreciated the reference to the Monty Hall problem in the first chapter of Think Bayes. In the past I have found the Monty Hall problem to be a very interesting example of how statistics can be unintuitive. Seeing how the Bayesian method explains how to apply knowledge to update the probability of an occurrence made a lot of sense to me and was a very useful way to think about the problem.
	As I started reading Eliezer Yudkowsky’s article on Baye’s Theorem. I must admit his declaration that, “soon you will be one of us” did not lead me to the belief that this would be a particularly educational article. However, I was interested in the description of the different ways to approach the same data regarding breast cancer and how the different framings cause different percentages of correct answers. Even after learning about Baye’s theorem and spending some class time working through examples I still found it difficult to apply the approach to the breast cancer example, and ended up being one of the people who needed to think about the problem in terms of a specific number of people rather than a percentage. Beyond seeing how the Bayesian approach leads to the answer for that example however, I found Yudkowsky’s language very repetition and overall I don’t think the post was a very good introduction to Bayesian Statistics.
	The second chapter of Think Bayes was very intriguing to me as it provided a very clear example of how to approach a statistic problem through python. I ended up spending a bit more time then necessary getting my development environment setup as I decided to try running python 3 in OSX both as a way to try to adapt the Think Bayes code to python 3, and to use my current development environment. However, I also went through the process of installing the desired dependencies on an Ubuntu VM to serve as a backup in case OSX fails to work at some point. I found the template pattern used in the Think Bayes library to be a really great approach to create a consistent API that works for a wide variety of problems while requiring minimum duplicate code. I particularly enjoyed writing a version of the Cookie problem that required memory of previously eaten cookies. This problem enabled me to remember much of the python syntax and style that I have not used for a while while also experimenting with the template pattern which is also new to me. I decided to approach the problem by making a bowl class that contained a dictionary mapping from type of cookie to quantity of cookie in the bowl. It also offered a “Total” function which returned the sum of all types of cookies it contained. While the class was a bit over engineered for the specific problem, it would work with any number of types of cookies and could be useful in a more complicated example. One of my personal goals for this class is to improve my skills at adapting mathematical and statistic problems to a computational approach so I was very excited to work towards a more generalized class that could be useful in a broader set of problems.
	The process of picking priors for many of the early problems was very easy as it was often defined in the problem statement. As a result, I had not given much thought to cases where it may be more difficult to interpret an accurate prior. Chapter 3 of Think Bayes explores the process of generating an informative and an uninformative prior. I was impressed by the degree to which making an assumption (like the power law assumption) in the locomotive problem caused the posteriors to converge as quickly as they did. I was also a bit surprised to see a defense of the more subjective informative prior, however the explanation that it is more reasonable to base the prior off of known information than to not use known information for the sake of objectivity seems to echo the idea of the Bayesian approach, that known information should have an effect on probability. As a result I found this chapter to be a compelling introduction to determining undefined priors.
	I have not yet started very in depth research about a topic to explore for my case study. However, before the start of the school year, I was discussing with courses with a family friend who is a cancer researcher at the Fred Hutch Cancer Research Center. He was very interested to hear that I was taking a class on Bayesian statistics and described how a number of research studies can greatly benefit in efficiency of time, quantity of drugs, and number of subjects used by approaching the research with the assumption that as results begin to come in the hypothesis showing the best results can be focused with a great proportion of resources to provide even more informational updates. The idea of optimizing or better understanding modern research being done strikes me as a very appropriate use of the Bayesian approach and is something I plan to look into further.